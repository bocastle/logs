# 동시성(Concurrency) vs 병렬성(Parallelism) 정리

> 요약: **동시성**은 작업을 **논리적으로 동시에** 진행되게 스케줄링하여 **응답성**을 높이고, **병렬성**은 여러 **코어/프로세서에서 물리적으로 동시에** 실행하여 **처리량/지연 시간**을 줄입니다.

---

## 1) 개념 정의

### 동시성(Concurrency)

- **한 개 이상의 작업이 겹치는 기간 동안 진행**되도록 조율하는 실행 모델입니다.
- 단일 코어에서도 **시간 분할**과 **컨텍스트 스위칭**으로 “동시에 보이게” 합니다.
- I/O 대기 시간 동안 **다른 작업으로 전환**하여 자원 활용도를 높입니다.

### 병렬성(Parallelism)

- **여러 코어/프로세서**가 **여러 작업을 물리적으로 동시에** 실행합니다.
- CPU 바운드 계산을 **분할**하여 **총 소요 시간**을 단축합니다.

---

## 2) 비교 표

| 구분          | 동시성(Concurrency)                 | 병렬성(Parallelism)                           |
| ------------- | ----------------------------------- | --------------------------------------------- |
| 실행 방식     | **인터리빙**(번갈아 실행)           | **동시 실행**(다중 코어)                      |
| 주요 목표     | **응답성·자원 활용** 극대화         | **처리량·지연 시간 단축**                     |
| 하드웨어 의존 | 낮음(단일 코어 가능)                | 높음(다중 코어 필요)                          |
| 적합 작업     | I/O 바운드, 대기 많은 워크로드      | CPU 바운드, 독립 계산 분할                    |
| 리스크        | 레이스, 교착, 기아, 스케줄링 복잡성 | 동기화 비용, 캐시 코히어런시, 파티셔닝 난이도 |
| 구현 요소     | 스레드/코루틴/이벤트 루프           | 다중 프로세스/스레드, SIMD, GPU 등            |

---

## 3) 예시 시나리오

### (1) 웹 서버

- **동시성 우위**: 요청/응답은 I/O 중심. 비동기 I/O(이벤트 루프, 코루틴)로 **수천 연결**을 효율적으로 처리.
- 병렬성 추가: 멀티코어에서 **워크 프로세스** 또는 **스레드 풀**로 동시성 루프를 **병렬**로 복제.

### (2) 이미지 변환/영상 인코딩

- **병렬성 우위**: 프레임/블록 단위로 분할하여 멀티코어·GPU로 **동시에 연산** → 처리시간 단축.
- 동시성 보완: 디스크 I/O/네트워크 I/O 파이프라인을 **오버랩**해 전체 파이프라인 지연을 최소화.

### (3) 검색 자동완성

- **동시성**: 사용자 입력 이벤트·네트워크 호출을 겹치게 처리해 **입력 랙 최소화**.
- 부분 병렬화: 대용량 인덱스 계산은 백엔드에서 **병렬 분산 처리**.

---

## 4) 성능 관점의 차이

- **동시성 → 응답성**  
  대기를 **숨기고** 다른 일로 전환. 평균 지연시간 감소, 스루풋은 상황에 따라 증가.
- **병렬성 → 처리량/지연 단축**  
  동일 작업을 **나눠 동시에 수행**. 이상적 스케일링은 `N`코어에 대해 `~N`배 성능이지만, 실제로는 **동기화/캐시 미스/메모리 대역폭**으로 제한.

---

## 5) 흔한 문제와 대응

### 동시성 이슈

- **Race Condition**: 원자성 보장(락, 트랜잭션, CAS), 불변 데이터 구조 사용.
- **Deadlock**: 락 순서 일관화, 타임아웃, 락 분해, 회로 차단기.
- **Starvation**: 공정한 스케줄링, 작업 선점 우선순위 조정.

### 병렬성 이슈

- **False Sharing/캐시 코히어런시**: 데이터 패딩, 파티션 분리, 로컬리티 개선.
- **부적절한 파티셔닝**: 균등 작업 분할, 워크 스틸링 스케줄러.
- **동기화 과다**: 락 범위 축소, 락 프리/리드-카피-업데이트(RCU), 배치 처리.

---

## 6) 선택 가이드

- **I/O 바운드**(DB/네트워크/파일): 먼저 **동시성**(비동기 I/O, 코루틴, 이벤트 루프)으로 처리량과 응답성 개선.
- **CPU 바운드**(수치연산/압축/정렬): **병렬성**으로 코어 자원 활용. 가능하면 **데이터 병렬**·SIMD·GPU 활용.
- **혼합 워크로드**: 파이프라인을 나눠 I/O 단계는 **동시성**, 계산 단계는 **병렬성**으로 **결합**.

---

## 7) 간단 의사코드 비교

### 동시성(이벤트 루프 스타일)

```pseudo
onRequest(req):
  fetchFromDB(req) async → await
  renderTemplate()
  respond()
# 이벤트 루프는 I/O 대기 중 다른 요청을 계속 처리
```

### 병렬성(멀티코어 분할)

```pseudo
parallel_for each chunk in split(data, cores):
  result[chunk] = compute(chunk)
merge(result)
```

---

## 8) 체크리스트

- [ ] 작업이 **I/O 바운드**인가 **CPU 바운드**인가?
- [ ] 상태 공유/경쟁이 있는가? → 락/불변/메시지 패싱 중 적절한 모델 선택.
- [ ] 데이터 파티셔닝이 가능한가? → 가능하면 **독립 청크**로 분리.
- [ ] 측정 기반인가? → 지표(지연, 처리량, CPU 사용률, 컨텍스트 스위칭)를 **프로파일링**.

---

## 결론

- **동시성**은 **대기 시간을 숨겨** 응답성을 높이고, **병렬성**은 **자원을 늘려** 처리량과 지연을 줄입니다.
- 실제 시스템은 둘을 **조합**합니다: 비동기 I/O로 **동시성**을 확보하고, 계산 구간은 **병렬화**하여 전체 성능을 최적화하십시오.
