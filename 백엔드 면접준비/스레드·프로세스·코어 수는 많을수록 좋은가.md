# 스레드·프로세스·코어 수는 많을수록 좋은가

> 결론: **무작정 많을수록 좋지 않습니다.** 작업 특성(CPU 바운드/IO 바운드), 런타임/OS 오버헤드, 메모리/캐시/락 경합, NUMA 구조 등 **시스템 제약**을 고려해 **측정 기반으로 상한을 찾는 것**이 최적의 접근입니다.

---

## 1) 기본 개념 요약

- **코어(Core)**: 실제 연산 장치. 물리 코어 위에 **하이퍼스레딩(논리 코어)** 이 추가될 수 있습니다.
- **프로세스(Process)**: 독립된 가상 메모리 공간 + 리소스 소유자. 안전하지만 **컨텍스트 스위칭/IPC 비용**이 큼.
- **스레드(Thread)**: 프로세스 내부의 실행 단위. 메모리 공유로 **경량**이나 **동기화 비용/버그 위험**이 존재.

---

## 2) “많을수록 좋지 않은” 이유

### 2.1 스레드 과다(Oversubscription)
- **컨텍스트 스위칭** 빈도 증가 → 캐시/파이프라인 오염, TLB 미스 증가.
- **락 경합**(mutex/spin lock), **false sharing**(캐시 라인 공유로 인한 쓰기 경합) 가중.
- **스택 메모리** 고정 비용 증가(스레드당 수백 KB~수 MB).

### 2.2 프로세스 과다
- **페이지 테이블/파일 디스크립터** 등 커널 오브젝트 증가 → 메모리 압박.
- **프로세스 스위치**는 스레드 스위치보다 **비용이 큼**.
- **IPC 비용**(파이프/소켓/공유메모리 동기화) 누적.

### 2.3 코어 과다(상대적 개념)
- **Amdahl 법칙**: 병렬화 불가능 비율이 성능 상한을 결정. 순차 부분이 10%면, 코어 무한대의 이론 최고 가속은 **10배**뿐.
- **메모리 대역/LLC(Last Level Cache)** 공유로 **메모리 바운드** 작업은 코어 추가 이득이 작음.
- **전력/발열/코어 간 인터커넥트** 제약, **NUMA**에서 원격 메모리 접근 비용 상승.

---

## 3) 하이퍼스레딩(논리 코어)의 함의

- **SMT**는 유휴 파이프라인 슬롯을 활용해 **처리량을 향상**시키지만, **단일 스레드 지연**은 개선이 제한적.
- **메모리/브랜치 미스 빈번**한 워크로드에서 효과가 큽니다. 반대로 **ALU 포화형**에서는 이득이 작거나 음수일 수 있습니다.

---

## 4) 워크로드별 권장 접근

### 4.1 CPU 바운드(압축, 암호화, 렌더링, 고정밀 계산)
- **스레드 ≈ 물리 코어 수(±하이퍼스레딩)** 로 시작, **바인딩/어피니티**로 코어 고정 시 지터 완화.
- **데이터 분할** 시 캐시 친화(블로킹/타일링), **false sharing** 회피(패딩).
- **락 없는 구조**(immutable 데이터, work stealing 큐) 고려.

### 4.2 IO 바운드(네트워크/디스크/DB)
- 스레드 수를 **코어 수보다 크게** 둘 수 있음. 단, **비동기/이벤트 루프**(NIO, epoll, io_uring)로 스레드 수를 제한하는 편이 대개 유리.
- **연결/큐 길이**로 역압(backpressure), **타임아웃/서킷 브레이커**로 지연 전파 차단.

### 4.3 혼합형(웹 서버)
- **요청 처리 파이프라인** 기준으로 **지배적 병목**(DB? JS 엔진? 템플릿?)을 찾아 **스레드/프로세스**를 조절.
- **프로세스 격리**(언어 런타임/GC/보안 요구)가 유리할 수 있음(예: Nginx + 앱 워커).

---

## 5) NUMA·캐시·메모리 고려

- **NUMA 노드** 간 원격 메모리 접근은 지연·대역 손실. 프로세스/스레드와 메모리를 **노드에 핀**(numactl, taskset).
- **메모리 대역**이 병목이면 코어 추가보다 **대역/캐시 효율** 개선이 우선.
- **HugePages**, **메모리 할당기**(jemalloc, tcmalloc) 선택이 영향을 줄 수 있음.

---

## 6) 튜닝 절차(측정 기반)

1. **목표 지표 설정**: 처리량(QPS), 지연(p95/p99), 비용/전력.
2. **기본값**: CPU 바운드 `= 코어 수`, IO 바운드 `= 코어 수 × (1~4)` 수준으로 시작.
3. **부하 테스트**: 스레드/프로세스/코어 매개변수 스윕(sweep) → **스루풋‑레이턴시 곡선** 도출.
4. **자원 지표 확인**: CPU 사용률, 런큐(run queue), 컨텍스트 스위치, LLC 미스, 메모리 대역, 소켓 대기.
5. **병목 원인 분석**: 락 프로파일링, flamegraph, eBPF/perf, async 프로파일러.
6. **점증적 조정**: **최적의 고원(plateau)** 구간에서 운영값 확정. 과도한 스레드로 **지연 꼬리(p99)** 가 늘지 않는지 확인.

> 참고: **리틀의 법칙** `L = λ × W` — 동시 실행 수(L)를 늘리면 대기(W)가 줄어드는 구간이 있으나, 임계점을 넘으면 반대로 **W가 급증**합니다.

---

## 7) 실무 체크리스트

- [ ] 워크로드가 **CPU/IO/메모리 바운드** 중 무엇인지 파악했는가
- [ ] **스레드/프로세스 수**가 **코어/메모리/캐시** 자원과 균형을 이루는가
- [ ] **하이퍼스레딩**의 유효성(득/실)을 실측했는가
- [ ] **락 경합/false sharing**을 측정·완화했는가
- [ ] **NUMA 어피니티** 및 메모리 배치를 고려했는가
- [ ] **비동기 모델**로 스레드 수를 제한할 수 있는가
- [ ] **부하 테스트**로 p95/p99/스루풋을 기준으로 최적점을 찾았는가

---

## 8) 요약

- 스레드·프로세스·코어는 **무작정 많을수록 성능이 오르지 않습니다.**
- **오버서브스크립션**, **락/캐시 경합**, **메모리/NUMA 제약**, **전력/발열**이 상한을 결정합니다.
- **작업 특성**에 맞춰 합리적인 시작점을 잡고, **측정 기반**으로 **최적점**을 찾는 것이 가장 경제적입니다.